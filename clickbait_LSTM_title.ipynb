{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import pandas as pd\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout, SpatialDropout1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.preprocessing import sequence, text\n",
    "import jsonlines\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from unidecode import unidecode\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_cores = 16\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=num_cores,\\\n",
    "        inter_op_parallelism_threads=num_cores, allow_soft_placement=True,\\\n",
    "        device_count = {'CPU' : 1, 'GPU' : 0})\n",
    "session = tf.Session(config=config)\n",
    "K.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readData(instance_path, truth_path):\n",
    "    instances = []\n",
    "    truths = []\n",
    "    \n",
    "    with jsonlines.open(instance_path) as reader:\n",
    "        for obj in reader:\n",
    "            obj['postText'] = obj['postText'][0]\n",
    "            instances.append(obj)\n",
    "    \n",
    "    with jsonlines.open(truth_path) as reader:\n",
    "        for obj in reader:\n",
    "            truths.append(obj)\n",
    "    \n",
    "    instance = pd.DataFrame.from_dict(instances)\n",
    "    label = pd.DataFrame.from_dict(truths)\n",
    "    data = pd.merge(instance, label, on='id')\n",
    "    \n",
    "    return data, instance, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainData, trainInstance, trainLabel = readData('../data/clickbait17-train-170331/instances.jsonl',\n",
    "               '../data/clickbait17-train-170331/truth.jsonl')\n",
    "validData, validInstance, validLabel = readData('../data/clickbait17-validation-170630/instances.jsonl',\n",
    "                     '../data/clickbait17-validation-170630/truth.jsonl')\n",
    "data_df = pd.concat([trainData, validData])\n",
    "instance_df = pd.concat([trainInstance, validInstance])\n",
    "label_df = pd.concat([trainLabel, validLabel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data_df['postText'].get_values()\n",
    "label = label_df['truthClass'].get_values()\n",
    "label[label == 'clickbait'] = 1\n",
    "label[label == 'no-clickbait'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 6875 11559 20539 ...,  1168 13390 10493] TEST: [ 9722  9291  9327 ..., 13364   728 15967]\n",
      "TRAIN: [  635  9588 10713 ...,  7055 16559  9482] TEST: [10472  1637  8258 ..., 16429  9610  3003]\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "X_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "for train_index, test_index in sss.split(data, label):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = data[train_index], data[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=0)\n",
    "for train_index, valid_index in sss.split(X_train, y_train):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", valid_index)\n",
    "    X_train, X_valid = X_train[train_index], X_train[valid_index]\n",
    "    y_train, y_valid = label[train_index], label[valid_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15837,), (4400,), (1760,))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tk = text.Tokenizer(num_words=200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tk.fit_on_texts(list(X_train) + list(X_test) + list(X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_len = 80\n",
    "\n",
    "X_train_title = tk.texts_to_sequences(X_train)\n",
    "X_train_title = sequence.pad_sequences(X_train_title, maxlen=max_len)\n",
    "\n",
    "X_test_title = tk.texts_to_sequences(X_test)\n",
    "X_test_title = sequence.pad_sequences(X_test_title, maxlen=max_len)\n",
    "\n",
    "X_valid_title = tk.texts_to_sequences(X_valid)\n",
    "X_valid_title = sequence.pad_sequences(X_valid_title, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_index = tk.word_index\n",
    "ytrain_enc = np_utils.to_categorical(y_train)\n",
    "ytest_enc = np_utils.to_categorical(y_test)\n",
    "yvalid_enc = np_utils.to_categorical(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# What is embedding? what is the dimension?\n",
    "model.add(Embedding(len(word_index) + 1, 300, input_length=80))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "\n",
    "model.add(LSTM(300, dropout=0.2, recurrent_dropout=0.2))\n",
    "\n",
    "model.add(Dense(200))\n",
    "model.add(PReLU())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(200))\n",
    "model.add(PReLU())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# adam = Adam(lr=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15837 samples, validate on 1760 samples\n",
      "Epoch 1/10\n",
      "15837/15837 [==============================] - 215s - loss: 0.6517 - acc: 0.7010 - val_loss: 0.5887 - val_acc: 0.7619\n",
      "Epoch 2/10\n",
      " 8032/15837 [==============>...............] - ETA: 102s - loss: 0.5827 - acc: 0.7433"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train_title, y=ytrain_enc,\n",
    "                 batch_size=32, epochs=10, verbose=1, validation_data = (X_valid_title, yvalid_enc),\n",
    "                 shuffle=True, initial_epoch = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluateModel(model, X, y):\n",
    "    pred = model.predict_proba(X)\n",
    "    print(classification_report(y[:,1], np.argmax(pred, axis = 1)))\n",
    "    print(accuracy_score(np.argmax(pred, axis = 1), y[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateModel(model, X_train_title, ytrain_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateModel(model, X_test_title, ytest_enc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
